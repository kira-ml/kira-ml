<div align="center">

# ğŸ‘‹ Hi, I'm Ken Ira Lacson

ğŸ“ Computer Science Undergraduate | ğŸ”¬ ML & NLP Researcher in Training  
ğŸ’¡ Passionate about language intelligence, deep learning, and building meaningful AI systems

</div>

---

## ğŸ§  About Me

I'm a Computer Science undergraduate deeply specializing in **Machine Learning**, with a focused research interest in **Natural Language Processing** and **Deep Learning**. My journey into AI began with the transformative rise of large language models, which sparked my fascination with how machines learn to represent, understand, and generate human language.

I maintain a **builder-researcher mindset**â€”constantly experimenting with new architectures and techniques while grounding my work in fundamental principles of linguistics, representation learning, and model mechanics.

---

## ğŸ”­ Research & Technical Focus

- **ğŸ§¬ Deep Learning for NLP**: Transformer architectures, attention mechanisms, and representation learning
- **ğŸ“š Language Modeling**: Pre-training, fine-tuning, and efficient adaptation techniques
- **ğŸ” Semantic Representations**: Embeddings, knowledge distillation, and interpretability methods
- **ğŸ› ï¸ MLOps Foundations**: Reproducible experimentation, model deployment, and evaluation frameworks

---

## ğŸ’» Technical Stack

**Programming Languages:**  
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-4479A1?style=flat&logo=postgresql&logoColor=white)

**ML & Deep Learning:**  
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)

**NLP Specialization:**  
![HuggingFace](https://img.shields.io/badge/ğŸ¤—_Transformers-FFD21E?style=flat&logo=huggingface&logoColor=black)
![spaCy](https://img.shields.io/badge/spaCy-09A3D5?style=flat&logo=spacy&logoColor=white)
![NLTK](https://img.shields.io/badge/NLTK-323330?style=flat)

**Tools & Platforms:**  
![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=flat)
![Git](https://img.shields.io/badge/Git-F05032?style=flat&logo=git&logoColor=white)

---

## ğŸš€ Featured Projects

### [Jurybee: Legal AI Agent](https://github.com/kira-ml/jurybee-proto)
Prototype AI system for legal text reasoning and claim analysis using retrieval-augmented generation and specialized legal embeddings.

**Tech:** LangChain Â· LegalBERT Â· RAG Â· Semantic Search

### [Tweet Intent Classifier](https://github.com/kira-ml/Inbound-vs-Outbound-Tweet-Classifier)
Transformer-based classification system that distinguishes between inbound customer queries and outbound corporate messaging.

**Tech:** Transformers Â· BERT Â· Scikit-learn Â· Text Classification

### [Multi-task Loan Risk Model](https://github.com/kira-ml/multi-task-default-interest-model)
Deep learning model performing simultaneous prediction of loan default risk and optimal interest rates using multi-task learning.

**Tech:** TensorFlow Â· XGBoost Â· Multi-task Learning

### [DeepDraw Digit Recognizer](https://github.com/kira-ml/DeepDraw-DigitRecognizer)
Interactive MNIST digit recognition system with custom drawing interface, demonstrating end-to-end ML application development.

**Tech:** Tkinter Â· Scikit-learn Â· Model Deployment

---

## ğŸ“ˆ Current Exploration

I'm currently deepening my understanding in:

- **Architecture Mechanics**: How transformer components learn linguistic representations
- **Efficient NLP**: Model compression, knowledge distillation, and parameter-efficient fine-tuning
- **Evaluation Methods**: Robust metrics for language model performance beyond accuracy
- **Semantic Search**: Dense retrieval systems and their applications in knowledge-intensive tasks

---

## ğŸŒŸ Aspirations

My long-term vision is to contribute to AI systems that genuinely understand and reason with languageâ€”moving beyond pattern recognition toward true language comprehension. I'm particularly interested in how we can build models that are not just statistically impressive but semantically grounded and interpretable.

I believe the next frontier in NLP lies in bridging the gap between human linguistic cognition and machine representation learning.

---

## ğŸ“« Let's Connect

I'm always open to discussing research ideas, collaborating on interesting projects, or learning from others in the ML/NLP community.

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Ken_Ira_Lacson-0A66C2?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/ken-ira-lacson-852026343/)
[![Email](https://img.shields.io/badge/Email-kenlacson15@gmail.com-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:kenlacson15@gmail.com)
[![GitHub](https://img.shields.io/badge/GitHub-kira--ml-181717?style=for-the-badge&logo=github)](https://github.com/kira-ml)
[![Kaggle](https://img.shields.io/badge/Kaggle-KeniraLacson-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)](https://www.kaggle.com/keniralacson)

</div>

---

<div align="center">

*"The most exciting research happens at the intersection of deep learning fundamentals and linguistic intelligence."*

</div>
